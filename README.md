# ğŸ“ Chatalogue â€” University Course Assistant Chatbot



<p align="center">
  <b>A Local, ML-Powered, Multi-Stage NLP System for University Course Queries</b><br/>
  9-Stage Pipeline â€¢ Custom spaCy NER â€¢ ML Intent Classification â€¢ Deterministic SQL â€¢ RAG + LLM
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-black.svg" alt="Python 3.10+" />
  <img src="https://img.shields.io/badge/Platform-Windows%20-black" alt="Cross-platform" />
  <img src="https://img.shields.io/badge/NLP-spaCy%20%7C%20SentenceTransformers-black" alt="NLP Stack" />
  <img src="https://img.shields.io/badge/Database-SQLite-black" alt="SQLite" />
  <img src="https://img.shields.io/badge/LLM-GPT--4.1--mini%20-black" alt="GPT-4.1-mini" />
</p>

---

## ğŸŒŸ Overview

**Chatalogue** is a complete, local-first university course chatbot built around a sophisticated **9-stage modular NLP pipeline**. It answers student questions about courses, instructors, schedules, locations, and more through an intuitive conversational interface.

### What can Chatalogue do?

- **"Who teaches Data Mining?"** â†’ Instructor lookup
- **"When does CS 521 meet and in which room?"** â†’ Schedule + location retrieval
- **"Where does that class meet?"** â†’ Contextual follow-up handling
- **"Who teaches Algorithms and when does Machine Learning meet?"** â†’ Multi-course queries

### Key Features

âœ… **Local-first architecture** â€” runs entirely offline except optional LLM enhancement  
âœ… **Custom ML models** â€” trained spaCy NER + SentenceTransformers intent classifier  
âœ… **Deterministic SQL generation** â€” safe, structured database queries  
âœ… **Context-aware** â€” remembers conversation history for follow-up questions  
âœ… **RAG-enhanced responses** â€” combines database results with LLM generation  
âœ… **Tkinter GUI** â€” clean, responsive chat interface  

---

## ğŸ§  The 9-Stage NLP Pipeline

Chatalogue processes every query through a sophisticated 9-stage pipeline:

<p align="center">
  <img src="pipeline.png" width="100%" alt="Pipeline Diagram" />
</p>

### ğŸ”µ NLP & Understanding (Stages 1â€“3)

**Stage 1: Intent Classification**
- ML-based classification using Logistic Regression + SentenceTransformers
- Determines user goal (course info, instructor lookup, schedule, location, etc.)
- Returns confidence scores and top-k predictions

**Stage 2: Semantic Parsing**
- Custom-trained spaCy NER model extracts entities
- Recognized entities: `COURSE_NAME`, `COURSE_CODE`, `INSTRUCTOR`, `BUILDING`, `TIME`, `WEEKDAY`, `SECTION`
- Multi-clause splitting: handles compound questions like "Who teaches DS and when does ML meet?"

**Stage 3: Context Handling**
- `ConversationContext` stores previous turns
- Resolves implicit references ("it", "that class", "the professor")
- Enables natural follow-up questions

### ğŸŸ  Data Retrieval (Stages 4â€“7)

**Stage 4: Fuzzy Search**
- Maps course names â†’ course codes using SQLite LIKE queries
- Handles variations: "deep learning" â†’ "MET CS 767"

**Stage 5: SQL Generation**
- `process_semantic_query()` builds safe, parameterized SQL
- Handles multi-course and multi-attribute queries
- Packages queries into structured "subqueries"

**Stage 6: Database Execution**
- `run_query.handle_request()` executes SQL on SQLite database
- Supports fuzzy search mode and structured multi-subquery mode
- Returns results as lists of dictionaries

**Stage 7: Context Update**
- New results stored in conversation state
- Enables chained queries: "Who teaches it?" â†’ "Where does it meet?"

### ğŸŸ¢ Response Generation (Stages 8â€“9)

**Stage 8: RAG Prompt Construction**
- `chatalogue.rag_answer_with_db()` merges DB results with prompt template
- Produces context-enriched query for LLM
- Structures data for optimal LLM comprehension

**Stage 9: LLM Response**
- Uses OpenAI API with GPT-4.1-mini
- Generates natural, conversational answers
- **Fully optional** â€” system works without API key (SQL-only mode)

---

## ğŸ“ Project Structure
```
project_root/
â”‚
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ mac_run.sh                       # macOS/Linux launch script
â”œâ”€â”€ win_run.bat                      # Windows launch script
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/                   # Processed data files
â”‚   â”œâ”€â”€ raw/                         # Raw scraped data
â”‚   â””â”€â”€ courses_metcs.sqlite         # SQLite database with course data
â”‚
â”œâ”€â”€ db_info.py                       # Database inspection utility
â”‚
â”œâ”€â”€ debug/
â”‚   â”œâ”€â”€ debug_query.py               # Query debugging tool
â”‚   â”œâ”€â”€ debug.py                     # General debugging utilities
â”‚   â””â”€â”€ str.py                       # String processing helpers
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ intent/                      # Intent classification model files
â”‚   â””â”€â”€ ner/                         # Custom spaCy NER model files
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ chatalogue/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ chat_window.py           # Tkinter GUI
â”‚       â”œâ”€â”€ chatalogue.py            # Main NLP engine & RAG
â”‚       â”œâ”€â”€ semantic_parser.py       # NER + intent override logic
â”‚       â”œâ”€â”€ intent_classifier.py     # ML classifier
â”‚       â”œâ”€â”€ db_interface.py          # SQL generation layer
â”‚       â”œâ”€â”€ run_query.py             # Database execution layer
â”‚       â”œâ”€â”€ bu_scraper.py            # Course web scraper
â”‚       â”œâ”€â”€ config.py                # Paths & constants
â”‚       â””â”€â”€ tempCodeRunnerFile.py    # Temporary execution file
â”‚
â”œâ”€â”€ testing/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ full_test.py             # Full integration tests
â”‚       â”œâ”€â”€ semantic_parser_test.py  # Parser unit tests
â”‚       â”œâ”€â”€ test_bot_result.txt      # Test result logs
â”‚       â”œâ”€â”€ test_chat.py             # Chat functionality tests
â”‚       â”œâ”€â”€ test_chatalogue.py       # Core engine tests
â”‚       â”œâ”€â”€ test_db_int.py           # Database interface tests
â”‚       â”œâ”€â”€ TEST_EDGE_CASES.py       # Edge case testing
â”‚       â”œâ”€â”€ test_intent.py           # Intent classifier tests
â”‚       â”œâ”€â”€ test_run_q.py            # Query execution tests
â”‚       â”œâ”€â”€ test_scraper.py          # Scraper tests
â”‚       â””â”€â”€ test_semantic_parser.py  # Additional parser tests
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ner_augment.py           # NER data augmentation
â”‚       â”œâ”€â”€ intent_train_model.py    # Intent model training script
â”‚       â””â”€â”€ ner_train_model.py       # NER model training script
â”‚
â””â”€â”€ pipeline.png                     # Pipeline diagram
```
---

## âš™ï¸ Installation

### Prerequisites

- Python 3.10 or higher
- pip package manager
- SQLite (included with Python)

### Setup Steps

1. **Clone the repository**
```bash
   git clone https://github.com/artisticdrake/Chatalogue.git
   cd Chatalogue
```

2. **Install dependencies**
```bash
   pip install -r requirements.txt
```

3. **Verify required files exist**
   - `data/courses_metcs.sqlite` â€” Course database
   - `models/intent/intent_model.joblib` â€” Intent classifier
   - `models/ner/course_ner_model/` â€” Custom NER model

4. **Configure OpenAI API**
```bash
   Set your environmental variable in your powershell using this command

   '$env:OPENAI_API_KEY = "your_api_key_here"'

```
   Without this, Chatalogue runs in SQL-only mode.

---

## ğŸš€ How to Run

### Windows (PowerShell)
```powershell
cd path/to/Chatalogue
$env:PYTHONPATH="src"
python -m chatalogue.chat_window
```

### macOS / Linux
```bash
chmod +x run.sh
./run.sh
```

**run.sh contents:**
```bash
#!/bin/bash
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
export PYTHONPATH="$SCRIPT_DIR/src"
python3 -m chatalogue.chat_window
```

---

## ğŸ’¬ Example Queries

| User Query | System Action |
|------------|---------------|
| "Who teaches Data Mining?" | Intent â†’ NER â†’ SQL â†’ Instructor name |
| "When does that class meet?" | Context resolution â†’ SQL â†’ Time & days |
| "Where does CS 544 meet?" | SQL lookup â†’ Room & building |
| "Who teaches ML and when does DS meet?" | Multi-course split â†’ iterative SQL â†’ merged output |

---

## ğŸ” Key Technical Components

### ğŸ”¹ Intent Classifier

**Location:** `src/chatalogue/intent_classifier.py`

- Uses **SentenceTransformers** (`all-MiniLM-L6-v2`) for text embeddings
- Trained **Logistic Regression** model
- Stored in: `models/intent_model.joblib`
- Outputs: predicted class, confidence score, top-k probabilities

### ğŸ”¹ Custom spaCy NER Model

**Location:** `models/course_ner_model/`

Recognizes the following entities:
- `COURSE_NAME` â€” "Data Mining", "Machine Learning"
- `COURSE_CODE` â€” "CS 521", "MET CS 767"
- `INSTRUCTOR` â€” "Prof. Smith", "Dr. Johnson"
- `BUILDING` â€” "CAS", "PSY", "MCS"
- `TIME` â€” "10:00", "18:00-20:45"
- `WEEKDAY` â€” "Monday", "Tue", "Wed"
- `SECTION` â€” "A1", "B2"

### ğŸ”¹ SQL Engine

**Components:**
- `db_interface.py` â€” Generates safe, parameterized SQL queries
- `run_query.py` â€” Executes queries against SQLite database
- Supports multi-subquery structures for complex multi-course questions
- Handles fuzzy matching and exact lookups

### ğŸ”¹ Tkinter GUI

**Location:** `src/chatalogue/chat_window.py`

Features:
- Clean, responsive chat interface
- Threaded message processing (non-blocking UI)
- Scrollable conversation history
- Action buttons: Save Chat, Clear, Test Query
- Real-time typing indicators

---

## ğŸ§ª Testing

You can test individual components programmatically:
```python
from chatalogue.chatalogue import chat_loop

ctx = None
answer, ctx = chat_loop("Who teaches Data Mining?", ctx)
print(answer)

# Follow-up question
answer, ctx = chat_loop("When does it meet?", ctx)
print(answer)
```

---

## ğŸ¤– RAG + LLM (Optional)

### With OpenAI API Key
If you configure an API key:
```bash
API_KEY = os.environ.get("OPENAI_API_KEY")
```

The system enhances database results with GPT-4.1-mini generated explanations for natural, conversational responses.

### Without API Key (SQL-Only Mode)
The system returns structured database results directly without LLM enhancement. Fully functional for all queries.

---

## ğŸ“¦ Dependencies
```txt
openai>=1.0.0
requests
beautifulsoup4
numpy
spacy>=3.7.0
sentence-transformers>=2.2.0
joblib
tqdm
lxml
```

**Note:** Tkinter is included with Python on Windows/macOS. PyTorch installs automatically with `sentence-transformers`.

---

## ğŸ› ï¸ Development Notes

### Running the Application
Always use the package entrypoint:
```bash
python -m chatalogue.chat_window
```
**Do not** run `.py` files directly.

### Code Structure
- Relative imports (`from . import ...`) are used throughout
- Database and model paths are centralized in `config.py`
- All modules are under `src/chatalogue/` package

### Extending the System
The modular architecture makes it easy to:
- Add new intents (modify `intent_classifier.py`)
- Expand NER entities (retrain `course_ner_model`)
- Add new database tables (update `db_interface.py`)
- Integrate new data sources (extend `bu_scraper.py`)

---


## ğŸ‘¨â€ğŸ’» Authors

**CS673 A1 Software Engineering (Fall 25) - GROUP 1**  


---

## ğŸ“„ Contributors

Repository and project content are maintained by the Chatalogue contributor.

---



<p align="center">
  <b>Built with â¤ï¸ by students, for students</b><br/>
  <i>Making university information accessible through conversation</i>
</p>